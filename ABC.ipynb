{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_n = 10\n",
    "replica_n = 2\n",
    "# the number of chosen samples\n",
    "top_n = 2\n",
    "\n",
    "import json\n",
    "SCHEMES_PATH = \"schemes.json\"\n",
    "with open(SCHEMES_PATH) as schemes_file:\n",
    "    schemes = json.load(schemes_file)[\"schemes\"]\n",
    "    \n",
    "run_flag = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define free parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "free_params = {\n",
    "#     \"AE_H_t\": [0,1],\n",
    "#     \"AE_L_t\": [0,1],\n",
    "#     \"B_MSC_rec\": [0.001,0.005],\n",
    "    \"B_MSC_Pr\": [0.01,0.05],\n",
    "#     \"B_MSC_Mo\": [0.0015,0.01],\n",
    "    \"CD_H_t\": [0.5,1],\n",
    "    \"CD_L_t\": [0,0.5]\n",
    "#     \"CD_M_t1\": 0.3,\n",
    "#     \"CD_M_t2\": 0.6,\n",
    "#     \"MG_H_t\": [15,40],\n",
    "#     \"MG_L_t1\": [0,10],\n",
    "#     \"MG_L_t2\": [3,15],\n",
    "#     \"Mo_H_v\": [2,5],\n",
    "#     \"Pr_N_v\": [0,1],\n",
    "#     \"w_lactate_ph\": [0.1,0.5],\n",
    "#     \"w_mg_ph\": [0.02,0.1],\n",
    "#     \"w_MI_lactate\": [0.05,0.1]\n",
    "}\n",
    "free_params_keys = list(free_params.keys())\n",
    "free_params_bounds = list(free_params.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def distance_function(realizations,expectations):\n",
    "    import numpy as np\n",
    "    distances = []\n",
    "    for i in range(len(realizations)):\n",
    "        raw_sim_data = realizations[i]\n",
    "        sim_data = {}\n",
    "        sim_liveCellCount = np.array(raw_sim_data[\"agents_count\"][\"MSC\"])\n",
    "        sim_totalCellCount = np.array(raw_sim_data[\"agents_count\"][\"MSC\"]) + np.array(raw_sim_data[\"agents_count\"][\"Dead\"])\n",
    "        sim_viability = sim_liveCellCount[-1]/sim_totalCellCount[-1] \n",
    "        sim_data.update({\"liveCellCount\":sim_liveCellCount,\n",
    "                         \"viability\": sim_viability})\n",
    "                \n",
    "        exp_data = expectations[i]\n",
    "\n",
    "        error_liveCellCount = (sim_data[\"liveCellCount\"] - np.array(exp_data[\"liveCellCount\"]))/np.array(exp_data[\"liveCellCount\"])\n",
    "        error_viability = (sim_data[\"viability\"] - np.array(exp_data[\"viability\"]))/np.array(exp_data[\"viability\"])\n",
    "\n",
    "        all_errors = np.concatenate((error_liveCellCount,error_viability),axis=0)\n",
    "        abs_all_errors = np.abs(all_errors)\n",
    "\n",
    "        distances.append(np.mean(abs_all_errors)) \n",
    "    \n",
    "    distance = np.mean(distances)\n",
    "    \n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/Users/matin/Downloads/testProjs/CA')\n",
    "import time\n",
    "import numpy as np\n",
    "class clock:\n",
    "    start_t = 0\n",
    "    end_t = 0\n",
    "    @staticmethod\n",
    "    def start():\n",
    "        clock.start_t = time.time()\n",
    "    @staticmethod\n",
    "    def end():\n",
    "        clock.end_t = time.time()\n",
    "        print('Elapsed time: ',clock.end_t - clock.start_t)\n",
    "\n",
    "import numpy as np\n",
    "class Process:\n",
    "    def __init__(self,free_params,sample_n):\n",
    "        self.free_params = free_params\n",
    "        self.free_params_keys = list(free_params.keys())\n",
    "        self.free_params_bounds = list(free_params.values())\n",
    "        self.sample_n = sample_n\n",
    "\n",
    "\n",
    "    def sample(self):\n",
    "        from diversipy import lhd_matrix\n",
    "        from diversipy import transform_spread_out\n",
    "        import json\n",
    "        # python version > 3.6\n",
    "        non_scalled_samples = transform_spread_out(lhd_matrix(self.sample_n, len(self.free_params))).transpose()\n",
    "        scaled_samples = []\n",
    "        ii = 0\n",
    "        for bounds in self.free_params_bounds:\n",
    "            low = bounds[0]\n",
    "            high = bounds[1]\n",
    "            \n",
    "            pre_samples_param = non_scalled_samples[ii]\n",
    "            \n",
    "            samples_param = list(map(lambda x:x*(high-low)+low ,pre_samples_param))\n",
    "            scaled_samples.append(samples_param)\n",
    "            ii+=1\n",
    "        priors = {key:value for key,value in zip(self.free_params_keys,scaled_samples)}\n",
    "        samples = np.array(scaled_samples).transpose()\n",
    "        np.savetxt('outputs/samples.txt', samples, fmt='%f')\n",
    "        ##### create parameter sets\n",
    "        param_sets = []\n",
    "        for sample in samples:\n",
    "            param_set = {}\n",
    "            for i in range(len(sample)):\n",
    "                sample_p = sample[i]\n",
    "                key = self.free_params_keys[i]\n",
    "                param_set.update({key:sample_p})\n",
    "            param_sets.append(param_set)\n",
    "        with open(\"outputs/param_sets.json\",'w') as file:\n",
    "            file.write(json.dumps({\"param_sets\":param_sets}))\n",
    "\n",
    "        self.param_sets = param_sets\n",
    "\n",
    "\n",
    "    param_sets = 0\n",
    "    sample_n = 0\n",
    "    def run_model(self,start_end):\n",
    "        import copy\n",
    "\n",
    "        start_n = start_end[0]\n",
    "        end_n = start_end[1]\n",
    "        distances = np.array([])\n",
    "    #     bar.start()\n",
    "        for i in range(start_n,end_n):\n",
    "            param_set = self.param_sets[i]\n",
    "    #         print(\"iteration \",i)\n",
    "            schemes_copy = copy.deepcopy(self.schemes)\n",
    "            rep_distances = []\n",
    "            for rep_i in range(self.replica_n):\n",
    "                try:\n",
    "                    sim_results_list = self.Model(param_set).run(schemes_copy)\n",
    "                except ValueError:\n",
    "                    # None value if the param set leads to invalid definition\n",
    "                    distances = np.append(distances,None) \n",
    "                    break\n",
    "                distance = self.distance_function(sim_results_list,self.expectations)\n",
    "                rep_distances.append(distance)\n",
    "            else:\n",
    "    #             print(rep_distances)\n",
    "                distances = np.append(distances,np.mean(rep_distances))\n",
    "    #         bar.update(i+1)\n",
    "    #     bar.finish()\n",
    "        return distances\n",
    "    expectations = 0    \n",
    "    replica_n = 0\n",
    "    Model = 0\n",
    "    distance_function = 0\n",
    "    schemes = 0\n",
    "    def run(self,CPU_n,Model, distance_function, schemes, replica_n):\n",
    "        import numpy as np\n",
    "        self.expectations = [scheme[\"expectations\"] for scheme in schemes]\n",
    "        self.replica_n = replica_n\n",
    "        self.Model = Model\n",
    "        self.distance_function = distance_function\n",
    "        self.schemes = schemes\n",
    "        from multiprocessing import Pool\n",
    "        CPU_n = 4\n",
    "\n",
    "        main_share = int(self.sample_n/CPU_n)\n",
    "        plus =  self.sample_n%CPU_n\n",
    "        indices =[np.array([x,x+1])*main_share for x in range(CPU_n)] \n",
    "        for i in range(plus):\n",
    "            indices[i][1]+=1\n",
    "\n",
    "        pl = Pool(CPU_n)\n",
    "        clock.start()\n",
    "        results = pl.map(self.run_model,indices)\n",
    "        clock.end()\n",
    "\n",
    "\n",
    "        distances = [] \n",
    "        for result in results:\n",
    "            distances = np.concatenate([distances,result],axis=0)\n",
    "\n",
    "        np.savetxt('outputs/distances.txt',np.array(distances),fmt='%s')\n",
    "\n",
    "from model import Model\n",
    "sys.path.insert(1, './src/')\n",
    "from process import Process\n",
    "if run_flag:\n",
    "    pr = Process(free_params=free_params,sample_n=sample_n)\n",
    "    pr.sample()\n",
    "    pr.run(CPU_n=CPU_n, Model=Model,distance_function=distance_function,schemes=schemes,replica_n = replica_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post processing:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_flag = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recover the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "distances = []\n",
    "with open(\"outputs/distances.txt\") as file:\n",
    "    for line in file:\n",
    "        line.strip()\n",
    "        try:\n",
    "            value = float(line)\n",
    "        except:\n",
    "            value = None\n",
    "        distances.append(value)\n",
    "samples = np.loadtxt('outputs/samples.txt', dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fitness values and plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "fitness_values = np.array([])\n",
    "for item in distances:\n",
    "    if item == None:\n",
    "        fitness = 0\n",
    "    else:\n",
    "        fitness = 1 - item\n",
    "    fitness_values = np.append(fitness_values,fitness)\n",
    "top_ind = np.argpartition(fitness_values, -top_n)[-top_n:]\n",
    "top_fitess_values = fitness_values[top_ind]\n",
    "np.savetxt(\"outputs/top_fitness.txt\",top_fitess_values,fmt='%f')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate posteriors\n",
    "- Extract the indices of min n values of distances\n",
    "- Extract the best fits\n",
    "- Extract associated samples\n",
    "- Create posteriors\n",
    "- Save posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "top_fit_samples = samples[top_ind]\n",
    "posteriors = {key:list(value) for key,value in zip(free_params_keys,top_fit_samples.transpose())}\n",
    "with open('outputs/posterior.json', 'w') as file:\n",
    "     file.write(json.dumps({'posteriors': posteriors}))\n",
    "# max(posteriors[\"B_MSC_Pr\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scale the posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalled_posteriors = {}\n",
    "for key,values in posteriors.items():\n",
    "    min_v = free_params[key][0]\n",
    "    max_v = free_params[key][1]\n",
    "    scalled = list(map(lambda x: (x-min_v)/(max_v-min_v),values))\n",
    "    scalled_posteriors.update({key:scalled})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box Plot: median, quartiles, and raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.offline\n",
    "def plot():\n",
    "    colors = ['rgba(93, 164, 214, 0.5)', 'rgba(255, 144, 14, 0.5)', 'rgba(44, 160, 101, 0.5)',\n",
    "              'rgba(255, 65, 54, 0.5)', 'rgba(207, 114, 255, 0.5)', 'rgba(127, 96, 0, 0.5)']\n",
    "    traces = []\n",
    "    ii = 0\n",
    "    for key,value in scalled_posteriors.items():\n",
    "        traces.append(go.Box(\n",
    "            y=value,\n",
    "            name=key,\n",
    "            boxpoints='all',\n",
    "            jitter=0,\n",
    "            fillcolor=colors[ii],\n",
    "            marker_size=5,\n",
    "            whiskerwidth=0.2,\n",
    "            line_width=2)\n",
    "                     )\n",
    "        ii += 1\n",
    "    layout = go.Layout(yaxis=dict(\n",
    "    #                             autorange=True,\n",
    "    #                             showgrid=False,\n",
    "                                dtick=0.2,\n",
    "                                zeroline = False,range= [-0.1,1.1]\n",
    "                                ),\n",
    "                        margin=dict(\n",
    "                                l=40,\n",
    "                                r=30,\n",
    "                                b=80,\n",
    "                                t=100\n",
    "                            ),\n",
    "                        showlegend=False,\n",
    "                        paper_bgcolor='rgb(243, 243, 243)',\n",
    "                        plot_bgcolor='rgb(243, 243, 243)',\n",
    "                       )\n",
    "    fig = { \"data\": traces,\"layout\":layout }\n",
    "    plotly.io.write_image(fig = { \"data\": traces,\"layout\":layout }, file=\"outputs/box_plot.svg\",format=\"svg\",scale=None, width=None, height=None)\n",
    "    # plotly.offline.plot(fig = { \"data\": traces,\"layout\":layout }, auto_open = True)\n",
    "if plot_flag:\n",
    "    plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot against empirical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model for posteriors\n",
    "The run function should be different in terms of collecting results of for all individual measurement points, running on the posterior param sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/Users/matin/Downloads/testProjs/CA')\n",
    "from model import Model\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "def AVERAGE_OVER_REPLICAS(items):\n",
    "    template = items[0][\"agents_count\"]\n",
    "    aver = {}\n",
    "    for key in template.keys():\n",
    "        stacks = [replica[\"agents_count\"][key] for replica in items]\n",
    "        stacks = np.array(stacks)\n",
    "        mean_v = np.mean(stacks,axis = 0)\n",
    "        aver.update({key:mean_v})\n",
    "    aver = {\"agents_count\":aver}\n",
    "#     print(aver,'\\n')\n",
    "    return aver\n",
    "def AVERAGE(replicas_schemes):\n",
    "    scheme_data = []\n",
    "    for scheme_i in range(len(schemes)):\n",
    "        replicas = [replica[scheme_i] for replica in replicas_schemes]\n",
    "        replicas_averaged = AVERAGE_OVER_REPLICAS(replicas)\n",
    "        scheme_data.append(replicas_averaged)  \n",
    "    return scheme_data\n",
    "\n",
    "def run_model_post(args):\n",
    "    full_results_repo = []\n",
    "    start_n = args[0]\n",
    "    end_n = args[1]\n",
    "    for i in range(start_n,end_n):\n",
    "        param_set = post_param_sets[i]\n",
    "        schemes_copy = copy.deepcopy(schemes)\n",
    "        sim_results_list_replicas = []\n",
    "        for rep_i in range(replica_n_post):\n",
    "            try:\n",
    "                sim_results_list = Model(param_set).run(schemes_copy)\n",
    "            except ValueError:\n",
    "                print(\"This cannot happen at this stage\")\n",
    "                sys.exit()\n",
    "            sim_results_list_replicas.append(sim_results_list)\n",
    "        else:\n",
    "            full_results_repo.append(AVERAGE(sim_results_list_replicas))\n",
    "    return full_results_repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agents_count': {'Dead': array([10.5, 23. , 47. ]), 'MSC': array([157. , 269.5, 371. ])}} \n",
      "\n",
      "{'agents_count': {'Dead': array([ 8. , 25. , 53.5]), 'MSC': array([167.5, 309. , 389. ])}} \n",
      "\n",
      "{'agents_count': {'Dead': array([10., 23., 54.]), 'MSC': array([165.5, 287. , 373.5])}} \n",
      "\n",
      "{'agents_count': {'Dead': array([ 6.5, 20. , 61.5]), 'MSC': array([169. , 328. , 389.5])}} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import json\n",
    "CPU_n = 4\n",
    "replica_n_post = 2\n",
    "\n",
    "with open(\"outputs/param_sets.json\") as file:\n",
    "    param_sets = json.load(file)[\"param_sets\"]\n",
    "    \n",
    "post_param_sets = np.array(param_sets)[top_ind]\n",
    "main_share = int(len(post_param_sets)/CPU_n)\n",
    "plus =  len(post_param_sets)%CPU_n\n",
    "indices =[np.array([x,x+1])*main_share for x in range(CPU_n)] \n",
    "for i in range(plus):\n",
    "    indices[i][1]+=1\n",
    "    \n",
    "pl = Pool(CPU_n)\n",
    "results = pl.map(run_model_post,indices)\n",
    "\n",
    "# Pile up the results\n",
    "full_results_repo = np.array([])\n",
    "for result in results:\n",
    "    if len(result) == 0:\n",
    "        continue\n",
    "    if len(full_results_repo) == 0:\n",
    "        full_results_repo = result\n",
    "    else:\n",
    "        full_results_repo = np.concatenate([full_results_repo,result],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[{'agents_count': {'Dead': array([10., 23., 54.]), 'MSC': array([165.5, 287. , 373.5])}},\n",
       "        {'agents_count': {'Dead': array([ 6.5, 20. , 61.5]), 'MSC': array([169. , 328. , 389.5])}}],\n",
       "       [{'agents_count': {'Dead': array([10.5, 23. , 47. ]), 'MSC': array([157. , 269.5, 371. ])}},\n",
       "        {'agents_count': {'Dead': array([ 8. , 25. , 53.5]), 'MSC': array([167.5, 309. , 389. ])}}]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_results_repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'liveCellCount': [120, 260, 370], 'viability': [0.95]},\n",
       " {'liveCellCount': [120, 240, 470], 'viability': [0.93]}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expectations = [scheme[\"expectations\"] for scheme in schemes]\n",
    "expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006296540126285333 0.9816881000486329\n",
      "0.0012593080252570666 0.1963376200097266\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LeveneResult(statistic=155.75629968290164, pvalue=9.475667695337911e-27)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "data1 = []\n",
    "data2 = []\n",
    "for i in range(100):\n",
    "    vv = random.random()\n",
    "    data1.append(vv)\n",
    "    data2.append(.2*vv)\n",
    "print(min(data1),max(data1))\n",
    "print(min(data2),max(data2))\n",
    "from scipy.stats import levene\n",
    "levene(data1,data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ABC",
   "language": "python",
   "name": "abc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
